/*
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    Nextflow config file for module tests
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    Defines input files and everything required to run a fast and simple pipeline test.
        nextflow run {{ name }} -profile test,<docker/singularity>
----------------------------------------------------------------------------------------
*/

// Global default params, used in configs
params {
    config_profile_name        = 'Test profile'
    config_profile_description = 'Minimal test dataset to check pipeline function'

    outdir = "${projectDir}/tests/subworkflows/local/prep_whole_read/output"
    tracedir         = "${params.outdir}/pipeline_info"
    publish_dir_mode = 'symlink'
    monochrome_logs  = false
    debug            = false
    ignore_params    = "run_genome_prep,run_input_check,run_trim_galore_fastqc,run_alignment,run_read_filter,run_umi_dedup,run_calc_crosslinks,run_peak_calling,run_reporting,only_input,only_genome,only_trimming,only_alignment,only_filtering,only_dedup,only_crosslinks,only_peakcalling"
    multiqc_title    = null

    // Max resource options
    max_memory       = '32.GB'
    max_cpus         = 8
    max_time         = '6.h'

    // Input params
    samplesheet                     = null
    fasta                           = null
    smrna_fasta                     = null
    gtf                             = null
    target_genome_index             = null
    smrna_genome_index              = null
    fasta_fai                       = null
    filtered_gtf                    = null
    chrom_sizes                     = null
    smrna_fasta_fai                 = null
    smrna_chrom_sizes               = null
    longest_transcript              = null
    longest_transcript_fai          = null
    longest_transcript_gtf          = null
    seg_gtf                         = null
    seg_filt_gtf                    = null
    seg_resolved_gtf                = null
    seg_resolved_gtf_genic          = null
    regions_gtf                     = null
    regions_filt_gtf                = null
    regions_resolved_gtf            = null
    regions_resolved_gtf_genic      = null

    // logic params
    only_moveumitoheader   = false
    only_input             = false
    only_genome            = false
    only_trimming          = false
    only_alignment         = false
    only_filtering         = false
    only_dedup             = false
    only_crosslinks        = false
    only_peakcalling       = false
    skip_fastqc            = false
    skip_trimming          = false
    skip_umi_dedupe        = false

    // Output params
    save_reference      = true
    save_indexes        = true
    save_merged_fastq   = true
    save_trimmed        = true
    save_align_intermed = true
    save_unaligned_res  = true

    // Pipeline params
    encode_eclip        = false
    move_umi_to_header  = false
    umi_header_format   = null
    save_unaligned      = true // DO NOT CHANGE
    umi_separator       = "rbc:"
    paraclu_min_value   = 10
    trimgalore_params   = "--fastqc --length 10 -q 20"
	bowtie_params       = "-v 2 -m 100 --norc --best --strata"
    star_params         = "--outFilterMultimapNmax 100 --outFilterMultimapScoreRange 1 --outSAMattributes All --alignSJoverhangMin 8 --alignSJDBoverhangMin 1 --outFilterType BySJout --alignIntronMin 20 --alignIntronMax 1000000 --outFilterScoreMin 10 --alignEndsType Extend5pOfRead1 --twopassMode Basic"
    clippy_params       = ""
    icount_peaks_params = ""
    peka_params         = ""

    // Whole read analysis params
    whole_read_analysis = false
    pairwise_samplesheet= null
    macs_gsize          = "hs"
    macs3_params        = "--keep-dup all --nomodel --extsize 30 --bdg"
}

// Process specifics settings
process {
        // WHOLE READ PREPARATION
        withName: 'BEDTOOLS_GENOMECOV_POS' {
            ext.args = '-bg -strand +'
            publishDir = [
                enabled: false
            ]
        }

        withName: 'BEDTOOLS_GENOMECOV_NEG' {
            ext.args = '-bg -strand -'
            publishDir = [
                enabled: false
            ]
        }

        // Transcriptome 
        withName: 'SAMTOOLS_VIEW_PLUS' {
            ext.prefix = { "${meta.id}_unique_transcriptome_plus" }
            ext.args   = "-F 16 --output-fmt bam"
            publishDir = [
                path: { "${params.outdir}/04_whole_read/transcriptome" },
                mode: "${params.publish_dir_mode}",
                enabled: params.save_align_intermed
            ]
        }

        withName: 'SAMTOOLS_VIEW_MINUS' {
            ext.prefix = { "${meta.id}_unique_transcriptome_neg" }
            ext.args   = "-f 16 --output-fmt bam"
            publishDir = [
                path: { "${params.outdir}/04_whole_read/transcriptome" },
                mode: "${params.publish_dir_mode}",
                enabled: params.save_align_intermed
            ]
        }

        withName: 'MERGE_AND_SORT' {
            ext.cmd1 = 'sort -k1,1 -k2,2n'
            ext.suffix = '.transcriptome'
            ext.ext = 'bedgraph'
            publishDir = [
                path: { "${params.outdir}/04_whole_read/transcriptome" },
                mode: "${params.publish_dir_mode}",
                saveAs: { filename -> filename.equals('versions.yml') ? null : filename }
            ]
        }

        withName: 'CROSSLINK_NORMCOVERAGE' {
            ext.cmd1 = 'awk -v total=\$CMD2 \'{printf "%s\\t%i\\t%i\\t%i\\n", \$1, \$2, \$3, 1000000*\$4/total}\' | sort -k1,1 -k2,2n'
            ext.cmd2 = 'awk \'BEGIN {total=0} {total = total + ($3 - $2) * ($4 < 0 ? -$4 : $4)} END {print total}\''
            ext.suffix = '.norm.transcriptome'
            ext.ext = 'bedgraph'
            publishDir = [
                path: { "${params.outdir}/04_whole_read/transcriptome" },
                mode: "${params.publish_dir_mode}",
                saveAs: { filename -> filename.equals('versions.yml') ? null : filename }
            ]
        }
}

// Load base.config by default for all pipelines
includeConfig '/nemo/lab/ulej/home/users/baih/PM24162/goodwright_clipseq/clipseq/conf/base.config'

// Load pipeline switching config
includeConfig '/nemo/lab/ulej/home/users/baih/PM24162/goodwright_clipseq/clipseq/conf/logic.config'

profiles {
    debug { process.beforeScript = 'echo $HOSTNAME' }
    crick { includeConfig '/nemo/lab/ulej/home/users/baih/PM24162/goodwright_clipseq/clipseq/conf/crick.config' }
    conda {
        conda.enabled          = true
        docker.enabled         = false
        singularity.enabled    = false
        podman.enabled         = false
        shifter.enabled        = false
        charliecloud.enabled   = false
    }
    mamba {
        conda.enabled          = true
        conda.useMamba         = true
        docker.enabled         = false
        singularity.enabled    = false
        podman.enabled         = false
        shifter.enabled        = false
        charliecloud.enabled   = false
    }
    docker {
        docker.enabled         = true
        docker.userEmulation   = true
        singularity.enabled    = false
        podman.enabled         = false
        shifter.enabled        = false
        charliecloud.enabled   = false
    }
    singularity {
        singularity.enabled    = true
        singularity.autoMounts = true
        docker.enabled         = false
        podman.enabled         = false
        shifter.enabled        = false
        charliecloud.enabled   = false
    }
    podman {
        podman.enabled         = true
        docker.enabled         = false
        singularity.enabled    = false
        shifter.enabled        = false
        charliecloud.enabled   = false
    }
    shifter {
        shifter.enabled        = true
        docker.enabled         = false
        singularity.enabled    = false
        podman.enabled         = false
        charliecloud.enabled   = false
    }
    charliecloud {
        charliecloud.enabled   = true
        docker.enabled         = false
        singularity.enabled    = false
        podman.enabled         = false
        shifter.enabled        = false
    }
    gitpod {
        executor.name          = 'local'
        executor.cpus          = 16
        executor.memory        = 60.GB
    }
    arm {
        docker.runOptions = '-u $(id -u):$(id -g) --platform=linux/amd64'
    }
}

// Set default registry for Apptainer, Docker, Podman and Singularity independent of -profile
// Will not be used unless Apptainer / Docker / Podman / Singularity are enabled
// Set to your registry if you have a mirror of containers
apptainer.registry   = 'quay.io'
docker.registry      = 'quay.io'
podman.registry      = 'quay.io'
singularity.registry = 'quay.io'

// Export these variables to prevent local Python/R libraries from conflicting with those in the container
// The JULIA depot path has been adjusted to a fixed path `/usr/local/share/julia` that needs to be used for packages in the container.
// See https://apeltzer.github.io/post/03-julia-lang-nextflow/ for details on that. Once we have a common agreement on where to keep Julia packages, this is adjustable.

env {
    PYTHONNOUSERSITE = 1
    R_PROFILE_USER   = "/.Rprofile"
    R_ENVIRON_USER   = "/.Renviron"
    JULIA_DEPOT_PATH = "/usr/local/share/julia"
}

// Capture exit codes from upstream processes when piping
process.shell = ['/bin/bash', '-euo', 'pipefail']

def trace_timestamp = new java.util.Date().format( 'yyyy-MM-dd_HH-mm-ss')
timeline {
    enabled = true
    file    = "${params.tracedir}/execution_timeline_${trace_timestamp}.html"
}
report {
    enabled = true
    file    = "${params.tracedir}/execution_report_${trace_timestamp}.html"
}
trace {
    enabled = true
    file    = "${params.tracedir}/execution_trace_${trace_timestamp}.txt"
}
dag {
    enabled = true
    file    = "${params.tracedir}/pipeline_dag_${trace_timestamp}.html"
}

manifest {
    name            = 'goodwright/clipseq'
    author          = ''
    homePage        = 'https://github.com/goodwright/clipseq'
    description     = ''
    mainScript      = 'main.nf'
    nextflowVersion = '!>=22.10.1'
    version         = '1.0dev'
    doi             = ''
}





// Function to ensure that resource requirements don't go beyond
// a maximum limit
def check_max(obj, type) {
    if (type == 'memory') {
        try {
            if (obj.compareTo(params.max_memory as nextflow.util.MemoryUnit) == 1)
                return params.max_memory as nextflow.util.MemoryUnit
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max memory '${params.max_memory}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'time') {
        try {
            if (obj.compareTo(params.max_time as nextflow.util.Duration) == 1)
                return params.max_time as nextflow.util.Duration
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max time '${params.max_time}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'cpus') {
        try {
            return Math.min( obj, params.max_cpus as int )
        } catch (all) {
            println "   ### ERROR ###   Max cpus '${params.max_cpus}' is not valid! Using default value: $obj"
            return obj
        }
    }
}

// Nextflow settings
nextflow.enable.configProcessNamesValidation = false